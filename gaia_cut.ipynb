{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library and Initalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your search path for Bovy's libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GAIA_TOOLS_DATA=/Users/john/Desktop/bovy_code/gaia_tools-master\n",
      "env: DUST_DIR=/Users/john/Desktop/bovy_code/mwdust-master\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/Users/john/Desktop/bovy_code/mwdust-master\")\n",
    "sys.path.insert(0, \"/Users/john/Desktop/bovy_code/gaia_tools-master\")\n",
    "sys.path.insert(0, \"/Users/john/Desktop/bovy_code/tgas-completeness-master/py\")\n",
    "sys.path.insert(0, \"/Users/john/Desktop/bovy_code/isodist-master\")\n",
    "\n",
    "%env GAIA_TOOLS_DATA=/Users/john/Desktop/bovy_code/gaia_tools-master\n",
    "%env DUST_DIR=/Users/john/Desktop/bovy_code/mwdust-master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few blocks import all the libraries. I receive **RunTimeError** messages from running *import numpy* concerning the version compatibility, but the program still runs anyways so I neglected it. There might also be *warning* message concerning Jo Bovy's *effsel.py*, which should not affect the code's running.\n",
    "\n",
    "The middle block contains just the variables Jo Bovy used to select tracer stars. Except for \"*max_plx_error*\", it is specific to Schutz's analysis to control the statistical behavior for the parallax uncertainty.\n",
    "\n",
    "The last two blocks Jovy Bovy's functions for the proper evfs generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/john/Desktop/bovy_code/tgas-completeness-master/py/effsel.py:32: RuntimeWarning: invalid value encountered in less_equal\n",
      "  sp_indx*= (numpy.roll((sp['JH']+sp['HK']),1)-(sp['JH']+sp['HK'])) <= 0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pylab\n",
    "import numpy as np\n",
    "import healpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import ICRS\n",
    "from astropy.coordinates import Galactic\n",
    "from galpy.util import bovy_plot, bovy_coords, save_pickles, multi\n",
    "from galpy.util.bovy_coords import cov_pmrapmdec_to_pmllpmbb\n",
    "\n",
    "import tqdm\n",
    "from scipy import interpolate, optimize, integrate\n",
    "import mwdust\n",
    "import effsel\n",
    "from isodist import Z2FEH, imf, PadovaIsochrone\n",
    "import gaia_tools.load, gaia_tools.select\n",
    "from effsel import main_sequence_cut_r, giant_sequence_cut\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "min_plx= 0.45/0.2\n",
    "max_dist = 1./min_plx\n",
    "tsf_jmin= 2.\n",
    "max_plx_error = 0.4\n",
    "\n",
    "def cyl_vol_func(X,Y,Z,xymin=0.,xymax=0.15,zmin=0.05,zmax=0.15):\n",
    "    \"\"\"A function that bins in cylindrical annuli around the Sun\"\"\"\n",
    "    xy = np.sqrt(X**2.+Y**2.)\n",
    "    out = np.zeros_like(X)\n",
    "    out[(xy >= xymin)*(xy < xymax)*(Z >= zmin)*(Z < zmax)]= 1.\n",
    "    return out\n",
    "\n",
    "def is_good_relplx(mj):\n",
    "    out= np.empty_like(mj)\n",
    "    out[mj > 5.] = 20.\n",
    "    out[mj < 0.] = 10.\n",
    "    out[(mj >= 0)*(mj <= 5.)] = 20.+2.*(mj[(mj >= 0)*(mj <= 5.)]-5.)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard initialization for the color spectrum, gaia data loading and absolute luminosity calculation. Color description using Johnson's **B-V** is possible but will not be implemented in this notebook. (Due to the heavy use of G stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp= effsel.load_spectral_types()\n",
    "tgas= gaia_tools.load.tgas()\n",
    "twomass= gaia_tools.load.twomass()\n",
    "#bv = twomass['b_m_opt']-twomass['vr_m_opt']\n",
    "jk = twomass['j_mag']-twomass['k_mag']\n",
    "dm = -5.*np.log10(tgas['parallax'])+10.\n",
    "mj = twomass['j_mag']-dm\n",
    "\n",
    "tsf= gaia_tools.select.tgasSelect( max_plxerr=max_plx_error )\n",
    "tsf._jmin= tsf_jmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cut flow of star density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce our cut flow modules.\n",
    "\n",
    "*cut_flow* : A function to streamline a list of cuts in the variable *cuts*. It takes a data array in the argument and return a length-reduced data with the cuts implemented. Arguments:\n",
    "    - data - np.array. Input data array.\n",
    "    - cuts - a list of boolean arrays. Each boolean array specifies which entries in *data* are to be removed.\n",
    "    \n",
    "Then we introduce our first cut. The *cut_general*,\n",
    "\n",
    "*cut_general* : Return a single-elemented boolean cut array list. It select the \"good\" statistics entries from the tgas data set. The return value is to be used by the *cut_flow* function.\n",
    "\n",
    "All future (more complicated) cuts will follow this programming flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_flow(data, cuts):\n",
    "   for i, cut_indx in enumerate(cuts):\n",
    "      data = data[cut_indx]\n",
    "   return data\n",
    "\n",
    "def cut_general(tgas):\n",
    "   stat_indx = tsf.determine_statistical(tgas,twomass['j_mag'],twomass['k_mag'])\n",
    "   tgas=tgas[stat_indx]\n",
    "   return [stat_indx]\n",
    "\n",
    "init_cuts = cut_general(tgas)\n",
    "\n",
    "tgas = cut_flow(tgas, init_cuts)\n",
    "twomass = cut_flow(twomass, init_cuts)\n",
    "jk= cut_flow(jk, init_cuts)\n",
    "dm= cut_flow(dm, init_cuts)\n",
    "mj= cut_flow(mj, init_cuts)\n",
    "\n",
    "print( 'tgas entry count: ', len(tgas) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cylindrical cut which cuts away stars with r > r_cyl_cut and |z| > z_cyl_cut in a cylindrical volume. Introducing a completeness volume early on will save computation time in the upcoming steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cyl_cut = 0.15\n",
    "z_cyl_cut = 0.22\n",
    "\n",
    "def cut_indx_vol(tgas, rcut, zcut):\n",
    "\n",
    "   XYZ= bovy_coords.lbd_to_XYZ(tgas['l'],tgas['b'],1./tgas['parallax'],degree=True)\n",
    "   r_cyl = np.sqrt(XYZ[:,0]**2.+XYZ[:,1]**2.)\n",
    "   z_cyl= XYZ[:,2]\n",
    "\n",
    "   return  [(r_cyl < r_cyl_cut)*(np.abs(z_cyl) < z_cyl_cut)]\n",
    "\n",
    "vol_cut_indx = cut_indx_vol(tgas, r_cyl_cut, z_cyl_cut)\n",
    "jk_cyl = cut_flow(jk, vol_cut_indx)\n",
    "mj_cyl = cut_flow(mj, vol_cut_indx)\n",
    "tgas_cyl = cut_flow(tgas, vol_cut_indx)\n",
    "\n",
    "print( 'Vol-reduced tgas entry count: ', len(tgas_cyl) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A module for dereddening. It is optional at this moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dereddening = False\n",
    "load_dereddened_data = False\n",
    "\n",
    "jk_corr = np.zeros_like(jk_cyl)\n",
    "mj_corr = np.zeros_like(mj_cyl)\n",
    "\n",
    "if (dereddening) and (not load_dereddened_data):\n",
    "   print(\"loading dust map...\")\n",
    "   #dust_combine = mwdust.Combined15()  #b-v filter\n",
    "   dust_combine_J = mwdust.Combined15(\"2MASS J\")\n",
    "   dust_combine_K = mwdust.Combined15(\"2MASS Ks\")\n",
    "   print(\"Preparing dereddening...\")\n",
    "   for i in tqdm.tqdm(range(len(jk_cyl))):\n",
    "      ldeg = (tgas_cyl['l'])[i]\n",
    "      bdeg = (tgas_cyl['b'])[i]\n",
    "      plx = (tgas_cyl['parallax'])[i]   \n",
    "      ej = dust_combine_J(ldeg,bdeg,np.divide(1000.,plx))\n",
    "      ek = dust_combine_K(ldeg,bdeg,np.divide(1000.,plx))\n",
    "      ejk = ej-ek\n",
    "      #ebv = dust_combine(ldeg,bdeg,np.divide(1000.,plx))\n",
    "      #bv_corr[i] = bv_cyl[i] - ebv\n",
    "      jk_corr[i] = jk_cyl[i] - ejk\n",
    "      mj_corr[i] = mj_cyl[i] - ej\n",
    "   dereddened_ouput_file = \"temp_ext.txt\"\n",
    "   np.savetxt(dereddened_ouput_file, np.transpose( np.array([jk_corr, mj_corr]) ), delimiter=',',header=\"B-V, M_j\")\n",
    "   print(\"dereddening complete! File saved to: \", dereddened_ouput_file)\n",
    "\n",
    "if dereddening and load_dereddened_data:\n",
    "   print(\"loading dereddened data\")\n",
    "   JKCOLUMN = 0; MJCOLUMN = 1\n",
    "   file_deredden = \"temp_ext.txt\" \n",
    "   jk_corr, mj_corr = np.genfromtxt(file_deredden, delimiter= \",\", usecols=(JKCOLUMN, MJCOLUMN), unpack=True, skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*find_jk_boundaries* : A function to find the color boundaries for a star category. Return a *2-tuple* with the first element being the \"upper\" boundary (smaller j-k) and the second element the \"lower\" boundary (larger j-k). Arguments:\n",
    "    - starCategory - string. The star's (sub-)category.\n",
    "    - sp - Jo Bovy's effsel spectral class array.\n",
    "\n",
    "I have defined the color boundaries for each star category to be the midpoints between its own midpoint and the midpoint of the adjacent star categories. Supported classes are\n",
    "- **All** stars\n",
    "- **A**, **F**, and **G** which contains only G0V to G4V\n",
    "- **Letter** + **number** labeled all subcategories, e.g. A0, G5, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jk_boundaries(starCategory, sp):\n",
    "\n",
    "   sp_stars = lambda star_Cat: np.array([( str(star_Cat) in s) for s in sp['SpT'] ], dtype='bool')\n",
    "   jk_color_cut_upper = float(\"nan\")\n",
    "   jk_color_cut_lower = float(\"nan\")\n",
    "\n",
    "   # First consider the input as main classes\n",
    "   if starCategory == \"A\":\n",
    "      jk_color_cut_upper = (  (sp['JH']+sp['HK'])[ sp_stars('B9V') ] + (sp['JH']+sp['HK'])[ sp_stars('A0V') ]  )/2\n",
    "      jk_color_cut_lower = (  (sp['JH']+sp['HK'])[ sp_stars('A9V') ] + (sp['JH']+sp['HK'])[ sp_stars('F0V') ]  )/2\n",
    "   elif starCategory == \"F\":\n",
    "      jk_color_cut_upper = (  (sp['JH']+sp['HK'])[ sp_stars('A9V') ] + (sp['JH']+sp['HK'])[ sp_stars('F0V') ]  )/2\n",
    "      jk_color_cut_lower = (  (sp['JH']+sp['HK'])[ sp_stars('F9V') ] + (sp['JH']+sp['HK'])[ sp_stars('G0V') ]  )/2\n",
    "   elif starCategory == \"G\": # THIS IS A SHORT-LISTED G CATEGORY\n",
    "      jk_color_cut_upper = (  (sp['JH']+sp['HK'])[ sp_stars('F9V') ] + (sp['JH']+sp['HK'])[ sp_stars('G0V') ]  )/2 \n",
    "      jk_color_cut_lower = (  (sp['JH']+sp['HK'])[ sp_stars('G4V') ] + (sp['JH']+sp['HK'])[ sp_stars('G5V') ]  )/2\n",
    "   elif starCategory == \"All\":\n",
    "      jk_color_cut_upper = (  (sp['JH']+sp['HK'])[ sp_stars('B9V') ] + (sp['JH']+sp['HK'])[ sp_stars('A0V') ]  )/2\n",
    "      jk_color_cut_lower = (  (sp['JH']+sp['HK'])[ sp_stars('G4V') ] + (sp['JH']+sp['HK'])[ sp_stars('G5V') ]  )/2      \n",
    "   else : # then consider the input as a subclass or a list of adjacent subclasses\n",
    "      for list_i, bo_val in enumerate(sp_stars(starCategory)):\n",
    "         if bo_val == True:\n",
    "            jk_color_cut_upper = (  (sp['JH']+sp['HK'])[list_i-1] + (sp['JH']+sp['HK'])[list_i]  )/2\n",
    "      for list_i, bo_val in enumerate( reversed(sp_stars(starCategory)) ):\n",
    "         if bo_val == True:\n",
    "            jk_color_cut_lower = (  (sp['JH']+sp['HK'])[len(sp)-list_i] + (sp['JH']+sp['HK'])[len(sp)-list_i-1]  )/2\n",
    "\n",
    "   return (jk_color_cut_upper, jk_color_cut_lower)\n",
    "\n",
    "#categories_to_be_plotted = [\"A0\",\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\"]  # uncomment me!\n",
    "categories_to_be_plotted = [\"A\",\"F\",\"G\"]  # uncomment me!\n",
    "categories_boundaries_u = np.array([]); categories_boundaries_l = np.array([]); categories_midpoints = np.array([]);\n",
    "\n",
    "for i, cat in enumerate(categories_to_be_plotted):\n",
    "   upper, lower = find_jk_boundaries(cat, sp)\n",
    "   mid = (upper + lower)/2.\n",
    "   categories_boundaries_u = np.append(categories_boundaries_u, upper)\n",
    "   categories_boundaries_l = np.append(categories_boundaries_l, lower)\n",
    "   categories_midpoints = np.append(categories_midpoints, mid)\n",
    "plt.scatter(range(len(categories_boundaries_u)), categories_boundaries_u, marker='|',color='red')\n",
    "plt.scatter(np.array(range(len(categories_boundaries_l)))+1, categories_boundaries_l, marker='|',color='red')\n",
    "plt.scatter(np.array(range(len(categories_midpoints)))+0.5, categories_midpoints, marker='o')\n",
    "plt.xticks(np.array(range(len(categories_midpoints)))+0.5,categories_to_be_plotted);plt.ylabel(\"j-k color\"); plt.title(\"color boundaries\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*generate_evfs* is a function that generate the complete effective volume for a certain class of stars specified by *mj_tight* and *jk_tight*. The return is a 2-tuple with the first element specifying the z-binning in a np.array; the second element specifying the evfs, which one-to-one corresponds to the bins in the first return element.\n",
    "\n",
    "*load_evfs* do the same thing as *generate_evfs*. But instead of numerical integration, it loads the evfs and the z-binning from a file.\n",
    "\n",
    "If *to_load_evfs* is used, **make sure the z-spatial grid between this program and the evfs file matches** (both the z-range and z steps).\n",
    "\n",
    "*cut_evfs* perform cut on the gaia stars so that the *mj* and *jk* after the cut will generate the correct evfs volume when they are passed to the *generate_evfs* function as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_evfs(mj_tight, jk_tight, spt, zspace, nintt_step = None, filename=\"default_evfs.txt\" , save=True):\n",
    "\n",
    "   zWidth = np.mean( (np.roll(zspace,-1) - zspace)[:-1] )\n",
    "   evfs = np.array([])\n",
    "\n",
    "   tesf= gaia_tools.select.tgasEffectiveSelect(tsf,dmap3d=mwdust.Zero(),MJ=mj_tight,JK=jk_tight,maxd=max_dist)\n",
    "   if nintt_step == None:\n",
    "      nintt_step = (2501*('A' in spt) + 1001 * (True-('A' in spt)))\n",
    "   \n",
    "   for i, z_i in enumerate(zspace):\n",
    "      zmin = z_i - zWidth/2.\n",
    "      zmax = z_i + zWidth/2.\n",
    "      \n",
    "      evfs = np.append(evfs, tesf.volume(lambda x,y,z: cyl_vol_func(x,y,z,xymax=r_cyl_cut,zmin=zmin,zmax=zmax), ndists=nintt_step,xyz=True,relative=True)   )\n",
    "\n",
    "   if save == True:\n",
    "      np.savetxt(filename, np.transpose( np.array([zspace, evfs]) ), delimiter=',',header=\"z_Bin_center, rel_effective_vol\", fmt='%10.5f')\n",
    "      \n",
    "   return (zspace, evfs)\n",
    "\n",
    "def load_evfs(filename=\"default_evfs.txt\"):\n",
    "   ZBINSCOLUMN = 0\n",
    "   EVFSCOLUMN = 1\n",
    "   zBins, evfs = np.genfromtxt(filename, delimiter= \",\", usecols=(ZBINSCOLUMN, EVFSCOLUMN), unpack=True, skip_header=1)\n",
    "   return (zBins, evfs)\n",
    "\n",
    "def cut_evfs(starCat, sp, jk, mj, tgas, cut_bright=False):\n",
    "   tightness = False\n",
    "   cut_indx = []\n",
    "\n",
    "   jk_color_cut_upper, jk_color_cut_lower = find_jk_boundaries(starCat, sp)\n",
    "\n",
    "   color_cut =  (jk > jk_color_cut_upper)*(jk < jk_color_cut_lower)\\\n",
    "    *(tgas['parallax']/tgas['parallax_error'] > (is_good_relplx(mj)))\\\n",
    "    *(jk != 0.)\n",
    "\n",
    "   jk_tight = jk[color_cut]\n",
    "   mj_tight = mj[color_cut]\n",
    "\n",
    "   if np.sum(color_cut) < 50:\n",
    "      good_mj_cut_tight = [True for k in range(mj_tight)]\n",
    "   else:\n",
    "      good_mj_cut_tight = (mj_tight > main_sequence_cut_r(jk_tight,tight=tightness))\\\n",
    "        *(mj_tight < main_sequence_cut_r(jk_tight,low=True,tight=tightness))\n",
    "   if cut_bright:\n",
    "      tjk= np.median(jk[good_mj_cut_tight])\n",
    "      tjmin= 8.-(tjk**2.+2.5*tjk)\n",
    "      tsf._jmin= tjmin\n",
    "   else:\n",
    "      tsf._jmin= 2.\n",
    "\n",
    "   return [color_cut, good_mj_cut_tight]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the evfs color-magnitude cut and generate the evfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_Cat = \"G\"\n",
    "zNBin_evfs = 100\n",
    "\n",
    "file_evfs = \"evfs_\" + star_Cat + \".txt\"\n",
    "to_load_evfs = False\n",
    "to_save_evfs = True\n",
    "\n",
    "zRangeList = []\n",
    "evfs_out = []\n",
    " \n",
    "data_list = []\n",
    "err_list = []\n",
    "binz_list = []\n",
    "\n",
    "print(\"Star Category: \", star_Cat)\n",
    "zStepWidth = 2*z_cyl_cut/(zNBin_evfs-1)\n",
    "zspace_evfs = np.linspace(-z_cyl_cut-zStepWidth/2., z_cyl_cut+zStepWidth/2., zNBin_evfs+1)\n",
    "\n",
    "if to_load_evfs:\n",
    "   print(\"Loaded evfs file: \", file_evfs)\n",
    "   zRangeList, evfs_out = load_evfs(filename=file_evfs)\n",
    "else:  \n",
    "   evfs_cuts = cut_evfs(star_Cat, sp, jk, mj, tgas)\n",
    "   mj_evfs = cut_flow(mj, evfs_cuts)\n",
    "   jk_evfs = cut_flow(jk, evfs_cuts)\n",
    "   _ , evfs_out = generate_evfs(mj_evfs, jk_evfs, star_Cat, zspace = zspace_evfs, filename=file_evfs, save=to_save_evfs)\n",
    "\n",
    "if to_save_evfs and not to_load_evfs:\n",
    "   data = np.transpose( np.array([zspace_evfs, evfs_out]) )\n",
    "   line_header = \"# z (pc), evfs\"\n",
    "   np.savetxt(file_evfs, data, delimiter=',',header=line_header)\n",
    "\n",
    "    \n",
    "plt.plot(zspace_evfs, evfs_out)\n",
    "plt.ylabel(\"volume\"); plt.xlabel(\"z (kpc)\"); plt.title(\"effective volumes (evfs)\")\n",
    "plt.show()\n",
    "\n",
    "print( 'star count after cut ', len(mj_evfs) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further cut the stars so that only the star category specified by the variable *star_Cat* remains. The evfs ( $\\Theta_i$ ) previous generated are stored as *evfs_weights* $w_i = \\Theta_i^{-1}$, which then will be stored in the output density file to be used to generate the physical star density.\n",
    "\n",
    "The code behind the commented line-breaker is just for the plots in this ipynb, and does no effect on the calculations that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_stars(starCat, sp, jk, mj, tgas): # category cut and volume cut\n",
    "   tightness = False\n",
    "   cut_indx = []\n",
    "\n",
    "   jk_color_cut_upper, jk_color_cut_lower = find_jk_boundaries(starCat, sp)\n",
    "\n",
    "   color_cut =  (jk > jk_color_cut_upper)*(jk < jk_color_cut_lower)*(tgas['parallax'] > min_plx)*(jk != 0.)\\\n",
    "    *( mj > main_sequence_cut_r(jk,tight=tightness))*(mj < main_sequence_cut_r(jk,low=True,tight=tightness))\\\n",
    "    *(tgas['parallax'] > min_plx)*(jk != 0.)\n",
    "\n",
    "   return [color_cut]\n",
    "\n",
    "\n",
    "if dereddening:\n",
    "   stars_cut = cut_stars(star_Cat, sp, jk_corr, mj_corr, tgas_cyl)\n",
    "if not dereddening:\n",
    "   stars_cut = cut_stars(star_Cat, sp, jk_cyl, mj_cyl, tgas_cyl)\n",
    "stars_categorized = cut_flow(tgas_cyl, stars_cut)\n",
    "jk_categorized = cut_flow(jk_cyl, stars_cut)\n",
    "mj_categorized = cut_flow(mj_cyl, stars_cut)\n",
    "\n",
    "ldeg = stars_categorized['l']\n",
    "bdeg = stars_categorized['b']\n",
    "plx = stars_categorized['parallax']\n",
    "XYZ= bovy_coords.lbd_to_XYZ(ldeg, bdeg, 1./plx, degree=True)\n",
    "z_kpc= XYZ[:,2]\n",
    "z_pc = XYZ[:,2]*1000.\n",
    "\n",
    "zRangeList_upper = zspace_evfs + zStepWidth/2\n",
    "zRangeList_lower = zspace_evfs - zStepWidth/2\n",
    "evfs_weight = np.array([])\n",
    "for i, z_i in enumerate(z_kpc):\n",
    "   zPosition_indx = (z_i < zRangeList_upper)*(z_i >= zRangeList_lower)\n",
    "   if np.sum(zPosition_indx) == 0:\n",
    "      print((\"star at z = \", z_i, \" kpc is out of evfs range!\"))\n",
    "   evfs_weight = np.append(evfs_weight, 1./evfs_out[zPosition_indx] )\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "dz_plt=0.025\n",
    "\n",
    "zspace_hist_plt = np.linspace( -z_cyl_cut,z_cyl_cut, int(2*z_cyl_cut/dz_plt)+1 )\n",
    "stars_plt_evfs, _, _ = plt.hist(z_kpc, zspace_hist_plt, weights=evfs_weight)\n",
    "stars_plt_evfs_err, _ , _ = plt.hist(z_kpc, zspace_hist_plt)\n",
    "for i, z_err in enumerate(stars_plt_evfs_err):\n",
    "   if z_err == 0:\n",
    "      continue\n",
    "   else :\n",
    "      stars_plt_evfs_err[i] = stars_plt_evfs[i]/np.sqrt(z_err)\n",
    "plt.clf()\n",
    "\n",
    "_ , (ax1, ax2) = plt.subplots(2, 1); plt.tight_layout(h_pad=5)\n",
    "\n",
    "bins_plt = (zspace_hist_plt + dz_plt/2.)[:-1]\n",
    "ax1.errorbar(bins_plt, stars_plt_evfs, yerr=stars_plt_evfs_err, capthick=2)\n",
    "ax1.set_title(\"star density\"); ax1.set_xlabel(\"z (kpc)\"); ax1.set_ylabel(\"count\")\n",
    "\n",
    "plt_norm = stars_plt_evfs[int(len(bins_plt)/2)]\n",
    "stars_plt_evfs_normed = stars_plt_evfs/plt_norm\n",
    "stars_plt_evfs_err_normed = stars_plt_evfs_err/plt_norm\n",
    "sechsq = lambda x, h, k: (0.25*k/h)*(np.cosh(x/(2.*h)) )**(-2)\n",
    "h_fit, h_fit_err = optimize.curve_fit( sechsq, bins_plt, stars_plt_evfs_normed ,  sigma=stars_plt_evfs_err_normed)\n",
    "print(\"Best-fit velocity h = \", h_fit[0], \" +/- \", h_fit_err[0,0])\n",
    "ax2.errorbar(bins_plt, stars_plt_evfs_normed, yerr=stars_plt_evfs_err_normed, capthick=2, label=\"data\")\n",
    "ax2.plot( bins_plt, sechsq(bins_plt, h_fit[0], h_fit[1]), label=\"$\\sech^2$ fit\")\n",
    "ax2.set_yscale('log'); ax2.legend();\n",
    "                                 \n",
    "ax2.set_title(\"star log-density\"); ax2.set_ylabel(\"log normalized density\"); ax2.set_xlabel(\"z (kpc)\");\n",
    "plt.show()\n",
    "\n",
    "print( 'star count after cut ', len(stars_categorized) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the proper motion from the ICRS coordiates (RA, Dec) to the galactic coordiates ( l, b ), which we will use to calculate the radial velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_file_density = star_Cat + '_stars.txt'\n",
    "\n",
    "def ProperMotionTransform(ra_coord, dec_coord, pmra_coord, pmdec_coord):\n",
    "   pmra_coord_cosdec = pmra_coord\n",
    "   icrs = ICRS(ra=ra_coord*units.degree, dec=dec_coord*units.degree, pm_ra_cosdec=pmra_coord_cosdec*units.mas/units.yr, pm_dec=pmdec_coord*units.mas/units.yr)\n",
    "   galactic = icrs.transform_to(Galactic)\n",
    "   pml = (galactic.pm_l_cosb)/np.cos(galactic.b.radian)/(units.mas/units.yr)\n",
    "   pmb = galactic.pm_b/(units.mas/units.yr)\n",
    "   return (pml, pmb)\n",
    "\n",
    "radeg = stars_categorized['ra']\n",
    "decdeg = stars_categorized['dec']\n",
    "pmra = stars_categorized['pmra']\n",
    "pmdec = stars_categorized['pmdec']\n",
    "\n",
    "pml, pmb = ProperMotionTransform(radeg, decdeg, pmra, pmdec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the measurement uncertainties (ony $\\delta z =$ *ErrZcoord* at the moment).\n",
    "\n",
    "All the information is output to the star density file (*save_file_density*), which will be the density data to compared with the prediction by the Poisson-Jeans solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hipID = stars_categorized['hip']\n",
    "e_plx = stars_categorized['parallax_error']\n",
    "err_pml = [0.  for k in range(len(stars_categorized)) ]\n",
    "covpm = [0.  for k in range(len(stars_categorized)) ]\n",
    "\n",
    "bRad = bdeg*np.pi/180.\n",
    "ErrZcoord = np.abs(np.divide(1000.,plx**2)*np.sin(bRad)*e_plx)\n",
    "\n",
    "\n",
    "if dereddening:\n",
    "   data = np.transpose( np.array([hipID,ldeg,bdeg,plx,e_plx,z_pc,evfs_weight, jk_categorized,mj_categorized, \\\n",
    "   mj_corr_categorized,jk_corr_categorized, pml,pmb,err_pml,covpm,covpm,ErrZcoord]) )\n",
    "else:\n",
    "   data = np.transpose( np.array([hipID,ldeg,bdeg,plx,e_plx,z_pc,evfs_weight, jk_categorized,mj_categorized, \\\n",
    "   mj_categorized,jk_categorized, pml,pmb,err_pml,covpm,covpm,ErrZcoord]) )\n",
    "\n",
    "line_header = \"# HpID, l (deg), b (deg), plx (mas), err_plx (mas), z_coord (pc), evfs_w, (B-V), AbsMag, AbsMag Corrected, \\\n",
    "(B-V) Corrected, pm_l (mas/yr), pm_b (mas/yr), err_pml (mas/yr) , err_pmb (mas/yr), cov_pmlpmb, err_z_coord (pc)\"\n",
    "\n",
    "np.savetxt(save_file_density, data, delimiter=',',header=line_header)\n",
    "\n",
    "print(\"Data saved to \", save_file_density)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "dz_mving_avg_plt=10; \n",
    "zspace_hist_plt = np.linspace( 0. ,z_cyl_cut*1000., int(z_cyl_cut*1000./dz_mving_avg_plt)+1 )\n",
    "stars_zerr_plt, _, _ = plt.hist(np.abs(z_pc), zspace_hist_plt, weights=ErrZcoord)\n",
    "stars_zerr_plt_norm, _, _ = plt.hist(np.abs(z_pc), zspace_hist_plt)\n",
    "plt.clf()\n",
    "\n",
    "plt.scatter(np.abs(z_pc), ErrZcoord, s = 0.1, label='data')\n",
    "plt.plot(zspace_hist_plt[:-1]+dz_mving_avg_plt/2, stars_zerr_plt/stars_zerr_plt_norm, color='red', label='moving average')\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"$\\delta z$ uncertainty\"); plt.ylabel(\"Uncertainty on $|z|$ (pc)\"); plt.xlabel(\"$|z|$ (pc)\"); plt.ylim(ymax=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
